---
title: "FinalProject"
output: html_document
date: "2023-12-06"
---

#load packages
```{r setup, include=FALSE}
library(tidyverse)
library(readr)
library(googledrive)
library(tidymodels)
library(caret)
library(rpart)
library(dplyr)
library(recipes)
library(patchwork)
library(yardstick)
library(parsnip)
library(vip)
library(GGally)
library(sf)
library(sf)
library(tidyverse)
library(janitor)
library(lubridate)
library(tidycensus)
library(httr)
library(jsonlite)
library(dotenv)
library(here)
library(testthat)
library(purrr)
library(roxygen2)
library(codetools)
library(tidymodels)
library(ggplot2)
library(vip)
library(GGally)
library(caret)
library(yardstick)
library(broom)
library(magrittr)
library(dplyr)
library(randomForest)
library(parsnip)
library(rpart.plot)
```

#load datasets
```{r}

#nightlight (viirs) data
viirs_drive <- drive_download(file = "viirs_annual_shrid.csv", overwrite = TRUE)
viirs_data <- read_csv("viirs_annual_shrid.csv")
file.remove("viirs_annual_shrid.csv")

#filter viirs data to 2012, keep average values (not median values)
viirs_data <- viirs_data %>%
  filter(year == 2012) %>%
  filter(category == "average-masked")

#poverty + consumption data 
secc_cons_drive <- drive_download(file = "secc_cons_rural_shrid1.csv", overwrite = TRUE)
secc_cons <- read_csv("secc_cons_rural_shrid1.csv")
file.remove("secc_cons_rural_shrid1.csv")

#social and economic caste census data
secc_caste_drive <- drive_download(file = "secc_rural_shrid.csv", overwrite = TRUE)
secc_caste <- read_csv("secc_rural_shrid.csv")
file.remove("secc_rural_shrid.csv")

#census abstract data (2011)
census_abstract_drive <- drive_download(file = "census_abstract.csv", overwrite = TRUE)
census_abstract <- read_csv("census_abstract.csv")
file.remove("census_abstract.csv")

#remove intermediate dfs
rm(viirs_drive)
rm(secc_cons_drive)
rm(secc_caste_drive)
rm(census_abstract_drive)

```


#parse dataframes
```{r}

#viirs
viirs_data <- viirs_data %>%
  mutate(shrid2_clone = shrid2) %>%
  separate(shrid2_clone, into = c("YY", "SS", "DDD", "sssss", "TTTTTT"), sep = "-", extra = "merge") 

#secc_cons
secc_cons <- secc_cons %>%
  mutate(shrid2_clone = shrid2) %>%
  separate(shrid2_clone, into = c("YY", "SS", "DDD", "sssss", "TTTTTT"), sep = "-", extra = "merge") 

#secc_caste
secc_caste <- secc_caste %>%
  mutate(shrid2_clone = shrid2) %>%
  separate(shrid2_clone, into = c("YY", "SS", "DDD", "sssss", "TTTTTT"), sep = "-", extra = "merge") 

#census abstract
census_abstract <- census_abstract %>%
  mutate(shrid2_clone = shrid2) %>%
  separate(shrid2_clone, into = c("YY", "SS", "DDD", "sssss", "TTTTTT"), sep = "-", extra = "merge") 

```

#create merged dataframes for each state
```{r}

#create state-specific versions of all four dataframes:

#madhya pradesh
viirs_data_mp <- viirs_data %>%
  filter(SS == 23)
secc_cons_mp <- secc_cons %>%
  filter(SS == 23)
secc_caste_mp <- secc_caste %>%
  filter(SS == 23)
census_abstract_mp <- census_abstract %>%
  filter(SS == 23)

#merge madhya pradesh data-frames
mp_list <- list(viirs_data_mp, secc_cons_mp, secc_caste_mp, census_abstract_mp) #put all data frames into list   
madhya_pradesh <- mp_list %>% 
  reduce(full_join, by='TTTTTT') #merge all data frames together

#assam
viirs_data_as <- viirs_data %>%
  filter(SS == 18)
secc_cons_as <- secc_cons %>%
  filter(SS == 18)
secc_caste_as <- secc_caste %>%
  filter(SS == 18)
census_abstract_as <- census_abstract %>%
  filter(SS == 18)

#merge assam data-frames
as_list <- list(viirs_data_as, secc_cons_as, secc_caste_as, census_abstract_as) #put all data frames into list   
assam <- as_list %>% 
  reduce(full_join, by='TTTTTT') #merge all data frames together
```

#madhya pradesh: data cleaning / ML set-up

```{r}
#filter to 2012
madhya_pradesh <- madhya_pradesh %>%
  filter(year == 2012)

#create testing and training datasets 
set.seed(12152023)
mp_split <- initial_split(data = madhya_pradesh, prop = 0.7)
mp_train <- training(x = mp_split)
mp_test <- testing(x = mp_split)

```

#madhya pradesh: data visualization w/ training dataset
```{r - Data Visualization (MP)}
#Graph 1: Histogram of Poverty Rate (MP)
ggplot(mp_train, aes(x=secc_pov_rate_rural)) + 
  geom_histogram() +
  geom_vline(xintercept = mean(mp_train$secc_pov_rate_rural), col = "red") +
  xlab("Percent of Rural Households Below Poverty Rate") +
  ylab("Count") +
  labs(title = "Rural Poverty Rate Distribution, Madhya Pradesh (Shrid-Level)")


#Graph 2: Poverty Rate vs Night Lights (MP)
mp_train %>%
  ggplot(aes(x = viirs_annual_mean, y = secc_pov_rate_rural)) +
  geom_point(alpha = 0.25) +
  labs(title = "Poverty rate vs. Night Light, Madhya Pradesh", 
       subtitle = "(Source: Socioeconomic & Caste Census 2011, VIIRS Night Lights 2012)") +
  xlab("Average Annual Night Light in Shrid") +
  ylab("Percent of Rural Households Below Poverty Line") +
  theme_minimal()

#Graph 3: Poverty Rate vs. Middle School Education (MP)
mp_train %>%
  ggplot(aes(x = ed_mid_share, y = secc_pov_rate_rural)) +
  geom_smooth(alpha = 0.5) +
  labs(title = "Level of Education vs. Poverty rate, Madhya Pradesh", 
       subtitle = "(Source: Socioeconomic & Caste Census 2011-2012)") +
  xlab("Share of Rural Population with Middle School Education") +
  ylab("Percent of Rural Households Below Poverty Line") +
  theme_minimal()

#Graph 4: Poverty Rate by Proportion of Population that is SC/ST

#create SC/ST proportion variable -- create duplicate train_EDA so as to not add extra columns to training df which are not present in test df
mp_train_EDA <- mp_train %>%
  mutate(sched_prop = (pc11_pca_p_sc + pc11_pca_p_st) / pc11_pca_tot_p)

#graph
mp_train_EDA %>%
ggplot(aes(x = sched_prop, y = secc_pov_rate_rural)) +
geom_smooth(alpha = 0.5) +
theme_linedraw() +
labs(
  x = "Proportion of Scheduled Caste/Tribe Proportion (Shrid)",
  y = "Percent of Rural Households Below Poverty Line",
  title = "Poverty Rate by Schedule Caste/Tribe Population Proportion, Madhya Pradesh",
  subtitle = "(Source: 2011 Population Census Abstract, Socioeconomic & Caste Census 2011)"
)

#Graph 5: Poverty Rate by Literacy Rate
#create total literacy rate variable
mp_train_EDA <- mp_train %>%
  mutate(lit_rate = (pc11_pca_p_lit) / pc11_pca_tot_p)

#graph 
mp_train_EDA %>%
ggplot(aes(x = lit_rate, y = secc_pov_rate_rural)) +
geom_smooth(alpha = 0.5) +
theme_linedraw() +
labs(
  x = "Literate Proportion of Population",
  y = "Poverty Rate",
  title = "Poverty Rate by Litercy Rate, Madhya Pradesh",
  subtitle = "(Source: 2011 Population Census Abstract, Socioeconomic & Caste Census 2011)"
)

#Graph 6: Poverty Rate by Proportion of Agricultural Employment

#create var for proportion of workers who are cultivators
mp_train_EDA <- mp_train %>%
  mutate(ag_prop = pc11_pca_main_cl_p/pc11_pca_tot_work_p)

#graph
mp_train_EDA %>%
ggplot(aes(x = ag_prop, y = secc_pov_rate_rural)) +
geom_smooth(alpha = 0.5) +
theme_linedraw() +
labs(
  x = "Proportion of Workers who are Cultivators",
  y = "Poverty Rate",
  title = "Poverty Rate by Agricultural Employment, Madhya Pradesh",
  subtitle = "((Source: 2011 Population Census Abstract, Socioeconomic & Caste Census 2011)"
)
```

#madhya pradesh: geospatial analysis
```{r}

#Reading in shrid shape file
shrid <- st_read("raw data/shrid2_open.shp", quiet = TRUE)
shrid <- st_transform(shrid, crs = 4326)

#Merging sf file into madhya_pradesh
madhya_pradesh_sf <- merge(madhya_pradesh, shrid, by = c("shrid2.x"))

#Converting data
madhya_pradesh_sf <- st_as_sf(madhya_pradesh_sf)
 

```

Madhya Pradesh: Model 1 - CART 

```{r}
#Coming up with a recipe for all the Madhya Pradesh models
mp_rec <- recipe(formula = secc_pov_rate_rural ~ ., data = mp_train) %>%
  step_zv(all_predictors()) %>%
  step_select(all_numeric()) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors()) %>%
  prep()
```


```{r}
#setting seed and v-fold cross-validation
set.seed(04281998)
folds <- vfold_cv(data = mp_train, v = 10, repeats = 1) 
```

```{r}
#coming up with a cart mod
cart_mod <-
  decision_tree() %>%
  set_engine(engine = "rpart") %>%
  set_mode(mode = "regression")

#Creating workflow 
cart_wf <- workflow() %>%
  add_recipe(mp_rec) %>%
  add_model(cart_mod)

#Fitting the model
cart_fit <- cart_wf %>%
  fit(data = mp_train)

#Creating a tree
tree_model <- rpart.plot::rpart.plot(x = cart_fit$fit$fit$fit)

```

```{r}
#plotting vip
cart_fit %>%
extract_fit_parsnip() %>%
vip(num_features = 10)

```

Model 2: Linear Regression 
```{r}
#create model object
lm_mod <- linear_reg() %>%
  set_engine("lm")

# create a workflow
lm_wf <- workflow() %>%
  add_recipe(mp_rec) %>%
  add_model(lm_mod) 

#function needed to extract coefficients
get_lm_coefs <- function(x) {
  
  x %>% 
    extract_fit_engine() %>% 
    tidy()
  
}

tidy_ctrl <- control_grid(extract = get_lm_coefs)

#fit 
lm_cv <- lm_wf %>%
  fit_resamples(resamples = folds, control = tidy_ctrl)

#measure RMSE 
collect_metrics(lm_cv, summarize = FALSE) %>%
 filter(.metric == "rmse") %>%
 ggplot(aes(id, .estimate, group = .estimator)) +
 geom_line() +
 geom_point() +
 scale_y_continuous(limits = c(0, 0.5)) +
 labs(title = "Calculated RMSE Across the 10 Folds",
 y = "RMSE_hat") +
 theme_minimal()



```

```{R}
#collecting metrics
metric_table_lm <- collect_metrics(lm_cv, summarize = TRUE)
metric_table_lm %>%
  filter(.metric == "rmse")
```

```{r}
#Getting coefficients
lm_coefs <- lm_cv %>% 
  select(id, .extracts) %>% 
  unnest(.extracts)  %>% 
  unnest(.extracts)

#Getting coefficients for night light
lm_coefs %>%
  filter(term == "viirs_annual_mean")
```


Model 3: LASSO
```{r}
#Lasso model
lasso_grid <- grid_regular(penalty(), levels = 10)

lasso_mod <- linear_reg(
  penalty = tune(), 
  mixture = 1,
) %>%
  set_engine("glmnet")

#creating wf
lasso_wf <- workflow() %>%
  add_recipe(mp_rec) %>%
  add_model(lasso_mod) 

#fitting wf 
lasso_cv <- lasso_wf %>%
  tune_grid(
    resamples = folds,
    grid = lasso_grid)

lasso_best <- lasso_cv %>%
  select_best(metric = "rmse")

#finalizing first wf 
lasso_final <- finalize_workflow(
  lasso_wf,
  parameters = lasso_best
)

lasso_coefs <- lasso_final %>%
  fit(data = train) %>%
  extract_fit_parsnip() %>%
  vi(lambda = lasso_best$penalty) 


#Coefficients for night light
lasso_coefs %>%
  filter(term == "viirs_annual_mean") %>%
  filter(step == 10)

```

```{r}
#fitting LASSO on testing data 
lasso_fit <- lasso_final %>%
  fit(data = mp_test)

#create predictions df
predictions_lasso <-
  bind_cols(
    test,
    stats::predict(object = lasso_fit, new_data = mp_test)
  )

# calculate the rmse on the testing data: 
rmse(data = predictions_lasso, truth = secc_pov_rate_rural, estimate = .pred)
```
