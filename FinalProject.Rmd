---
title: "Final Project"
author: "Alekhya Chaparala, Jacob Ausubel, Juliet Hayes, Saloni Bhatia"
date: "12/14/23"
format:
  html:
    embed-resources: true
    self-contained: true
execute: 
  warning: false
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Load packages

```{r, message = FALSE, warning = FALSE}
#Loading packages
library(tidyverse)
library(readr)
library(googledrive)
library(tidymodels)
library(caret)
library(rpart)
library(dplyr)
library(recipes)
library(patchwork)
library(yardstick)
library(parsnip)
library(vip)
library(GGally)
library(sf)
library(tidyverse)
library(janitor)
library(lubridate)
library(tidycensus)
library(httr)
library(jsonlite)
library(dotenv)
library(here)
library(testthat)
library(purrr)
library(roxygen2)
library(codetools)
library(tidymodels)
library(ggplot2)
library(vip)
library(GGally)
library(caret)
library(yardstick)
library(broom)
library(magrittr)
library(dplyr)
library(randomForest)
library(parsnip)
library(rpart.plot)
library(patchwork)
library(purrr)
library(rgdal)
```


```{r}
#setting up drive 
drive_auth(
  email = gargle::gargle_oauth_email(),
  path = NULL,
  subject = NULL,
  scopes = "drive",
  cache = gargle::gargle_oauth_cache(),
  use_oob = gargle::gargle_oob_default(),
  token = NULL
)
```

#Load datasets

```{r, message = FALSE, warning = FALSE}
#nightlight (viirs) data
viirs_drive <- drive_download(file = "viirs_annual_shrid.csv", overwrite = TRUE)
viirs_data <- read_csv("viirs_annual_shrid.csv")
file.remove("viirs_annual_shrid.csv")

#filter viirs data to 2012, keep average values (not median values)
viirs_data <- viirs_data %>%
  filter(year == 2012) %>%
  filter(category == "average-masked")

#poverty + consumption data 
secc_cons_drive <- drive_download(file = "secc_cons_rural_shrid1.csv", overwrite = TRUE)
secc_cons <- read_csv("secc_cons_rural_shrid1.csv")
file.remove("secc_cons_rural_shrid1.csv")

#social and economic caste census data
secc_caste_drive <- drive_download(file = "secc_rural_shrid.csv", overwrite = TRUE)
secc_caste <- read_csv("secc_rural_shrid.csv")
file.remove("secc_rural_shrid.csv")

#census abstract data (2011)
census_abstract_drive <- drive_download(file = "census_abstract.csv", overwrite = TRUE)
census_abstract <- read_csv("census_abstract.csv")
file.remove("census_abstract.csv")

#remove intermediate dfs
rm(viirs_drive)
rm(secc_cons_drive)
rm(secc_caste_drive)
rm(census_abstract_drive)

```

#Parse dataframes

```{r, message = FALSE, warning = FALSE}

#viirs
viirs_data <- viirs_data %>%
  mutate(shrid2_clone = shrid2) %>%
  separate(shrid2_clone, into = c("YY", "SS", "DDD", "sssss", "TTTTTT"), sep = "-", extra = "merge") 

#secc_cons
secc_cons <- secc_cons %>%
  mutate(shrid2_clone = shrid2) %>%
  separate(shrid2_clone, into = c("YY", "SS", "DDD", "sssss", "TTTTTT"), sep = "-", extra = "merge") 

#secc_caste
secc_caste <- secc_caste %>%
  mutate(shrid2_clone = shrid2) %>%
  separate(shrid2_clone, into = c("YY", "SS", "DDD", "sssss", "TTTTTT"), sep = "-", extra = "merge") 

#census abstract
census_abstract <- census_abstract %>%
  mutate(shrid2_clone = shrid2) %>%
  separate(shrid2_clone, into = c("YY", "SS", "DDD", "sssss", "TTTTTT"), sep = "-", extra = "merge") 

```

#Create merged dataframes for each state

```{r, message = FALSE, warning = FALSE}

#create state-specific versions of all four dataframes:

#madhya pradesh (State Code = 23)
viirs_data_mp <- viirs_data %>%
  filter(SS == 23)
secc_cons_mp <- secc_cons %>%
  filter(SS == 23)
secc_caste_mp <- secc_caste %>%
  filter(SS == 23)
census_abstract_mp <- census_abstract %>%
  filter(SS == 23)

#merge madhya pradesh data-frames
mp_list <- list(viirs_data_mp, secc_cons_mp, secc_caste_mp, census_abstract_mp)

madhya_pradesh <- Reduce(function(x, y) full_join(x, y, by = 'TTTTTT'), mp_list)

#assam (State Code = 18)
viirs_data_as <- viirs_data %>%
  filter(SS == 18)
secc_cons_as <- secc_cons %>%
  filter(SS == 18)
secc_caste_as <- secc_caste %>%
  filter(SS == 18)
census_abstract_as <- census_abstract %>%
  filter(SS == 18)

#merge assam data-frames
as_list <- list(viirs_data_as, secc_cons_as, secc_caste_as, census_abstract_as)
assam <- Reduce(function(x, y) full_join(x, y, by = 'TTTTTT'), as_list)
 #merge all data frames together

#remove duplicates
assam<- select(assam, -matches("_data2"))
```

#Madhya Pradesh: data cleaning / ML set-up

```{r, message = FALSE, warning = FALSE}
#checking for missing values merged MP dataset 
#is_na_madhya_pradesh <- is.na(madhya_pradesh)
#print(is_na_madhya_pradesh)

#There are missing values 
#any_missing_madhya_pradesh <- any(is.na(madhya_pradesh))
#print(any_missing_madhya_pradesh)

#filter to 2012
madhya_pradesh <- madhya_pradesh %>%
  filter(year == 2012)

#create testing and training datasets 
set.seed(12152023)
mp_split <- initial_split(data = madhya_pradesh, prop = 0.7)
mp_train <- training(x = mp_split)
mp_test <- testing(x = mp_split)

#dropping missing values (MP)
mp_train <-
  mp_train %>%
  na.omit()

#dropping missing values (MP)
mp_test <-
  mp_test %>%
  na.omit()
```

#Assam: Data cleaning / ML set-up

```{r, message = FALSE, warning = FALSE}

#checking for missing values merged Assam dataset 
#is_na_assam <- is.na(assam)
#print(is_na_assam)

#There are missing values 
#any_missing_assam <- any(is.na(assam))
#print(any_missing_assam)

#filter to 2012
assam <- assam %>%
 filter(year == 2012)

#create testing and training datasets 
set.seed(12152023)
as_split <- initial_split(data = assam, prop = 0.7)
as_train <- training(x = as_split)
as_test <- testing(x = as_split)

#dropping missing values (assam)
as_train <-
  as_train %>%
  na.omit()

#dropping missing values (assam)
as_test <-
  as_test %>%
  na.omit()
```

#Data visualization w/training dataset

```{r, message = FALSE, warning = FALSE}

#A: Histograms of Poverty Rate by State

#Madhya Pradesh
plot1 <- ggplot(mp_train, aes(x=secc_pov_rate_rural)) + 
  geom_histogram() +
  geom_vline(xintercept = mean(mp_train$secc_pov_rate_rural, na.rm = TRUE), col = "red") +
  xlab("% of Shrid Households in Poverty") +
  ylab("Count") +
  labs(title = "Madhya Pradesh") +
  theme_minimal() + 
  theme(
    axis.title = element_text(size = 8), 
    axis.text = element_text(size = 8),
    plot.title = element_text(size = 10)
  )

#Assam
plot2 <- ggplot(as_train, aes(x=secc_pov_rate_rural)) + 
  geom_histogram() +
  geom_vline(xintercept = mean(as_train$secc_pov_rate_rural, na.rm = TRUE), col = "red") +
  xlab("% of Shrid Households in Poverty") +
  ylab("Count") +
  labs(title = "Assam") +
  theme_minimal() + 
  theme(
    axis.title = element_text(size = 8), 
    axis.text = element_text(size = 8),
    plot.title = element_text(size = 10)
  )

#side-by-side
plot_combined <- plot1 + plot2 +
  plot_annotation(title = "Rural Poverty Distribution") 
print(plot_combined)


#B: Poverty Rate vs Night Lights 

#Madhya Pradesh

plot3 <- mp_train %>%
  ggplot(aes(x = viirs_annual_mean, y = secc_pov_rate_rural)) +
  geom_point(alpha = 0.25) + 
  scale_x_continuous(
    name = "Average Night Light Radiance (nW/cm^2/sr)"
  ) +
  scale_y_continuous(
    name = "% of Shrid Households in Poverty"
  ) +
  labs(title = "Madhya Pradesh") +

  theme_minimal() +
  theme(
    axis.title = element_text(size = 8), 
    axis.text = element_text(size = 8),
    plot.title = element_text(size = 10)
  )

#Assam
plot4 <- as_train %>%
   ggplot(aes(x = viirs_annual_mean, y = secc_pov_rate_rural)) + 
  geom_point(alpha = 0.25) +
  scale_x_continuous(
    name = "Average Night Light Radiance (nW/cm^2/sr)"
  ) +
  scale_y_continuous(
    name = "% of Shrid Households in Poverty"
  ) +
   labs(title = "Assam") +
  theme_minimal() + 
  theme(
    axis.title = element_text(size = 8), 
    axis.text = element_text(size = 8),
    plot.title = element_text(size = 10)
  )

#side-by-side
plot_combined <- plot3 + plot4  +
  plot_annotation(title = "Shrid Poverty Rate vs. Night Light")
plot_combined

#C: Poverty Rate vs. Middle School Education 

#Madhya Pradesh
plot5 <- mp_train %>%
  ggplot(aes(x = ed_mid_share, y = secc_pov_rate_rural)) +
  geom_smooth(alpha = 0.5) +
  labs(title = "Madhya Pradesh") +
  xlab("Share of Rural Population with Middle School Education") +
  ylab("Percent of Rural Households Below Poverty Line") +
  theme_minimal()  + 
  theme(
    axis.title = element_text(size = 8), 
    axis.text = element_text(size = 8),
    plot.title = element_text(size = 10)
  )

#Assam
plot6 <- as_train %>%
  ggplot(aes(x = ed_mid_share, y = secc_pov_rate_rural)) +
  geom_smooth(alpha = 0.5) +
  labs(title = "Assam") +
  xlab("Share of Rural Population with Middle School Education") +
  ylab("Percent of Rural Households Below Poverty Line") +
  theme_minimal()  + 
  theme(
    axis.title = element_text(size = 8), 
    axis.text = element_text(size = 8),
    plot.title = element_text(size = 10)
  )

#side-by-side
plot_combined <- plot5 + plot6 +
  plot_annotation(title = "Middle School Graduate Rate vs. Poverty Rate")
plot_combined

#D: Poverty Rate by Proportion of Population that is SC/ST

#create SC/ST proportion variable -- create duplicate train_EDA so as to not add extra columns to training df which are not present in test df
mp_train_EDA <- mp_train %>%
  mutate(sched_prop = (pc11_pca_p_sc + pc11_pca_p_st) / pc11_pca_tot_p)
as_train_EDA <- as_train %>%
  mutate(sched_prop = (pc11_pca_p_sc + pc11_pca_p_st) / pc11_pca_tot_p)

#Madhya Pradesh
plot7 <- mp_train_EDA %>%
ggplot(aes(x = sched_prop, y = secc_pov_rate_rural)) +
geom_smooth(alpha = 0.5) +
theme_linedraw() +
labs(
  x = "% Scheduled Caste/Tribe",
  y = "Percent of Rural Households Below Poverty Line",
  title = "Madhya Pradesh" 
)  + 
  theme(
    axis.title = element_text(size = 8), 
    axis.text = element_text(size = 8),
    plot.title = element_text(size = 10)
  ) +
  theme_minimal()

#Assam
plot8 <- as_train_EDA %>%
ggplot(aes(x = sched_prop, y = secc_pov_rate_rural)) +
geom_smooth(alpha = 0.5) +
theme_linedraw() +
labs(
  x = "% Scheduled Caste/Tribe",
  y = "Percent of Rural Households Below Poverty Line",
  title = "Assam") + 
  theme(
    axis.title = element_text(size = 8), 
    axis.text = element_text(size = 8),
    plot.title = element_text(size = 10)
  ) +
  theme_minimal()

#side-by-side
plot_combined <- plot7 + plot8 +
  plot_annotation(title = "Scheduled Caste/Tribe Population vs. Poverty Rate")
plot_combined


#E: Poverty Rate by Literacy Rate
#create total literacy rate variable
mp_train_EDA <- mp_train %>%
  mutate(lit_rate = (pc11_pca_p_lit) / pc11_pca_tot_p)
as_train_EDA <- as_train %>%
  mutate(lit_rate = (pc11_pca_p_lit) / pc11_pca_tot_p)

#Madhya Pradesh
plot9 <- mp_train_EDA %>%
ggplot(aes(x = lit_rate, y = secc_pov_rate_rural)) +
geom_smooth(alpha = 0.5) +
theme_linedraw() +
labs(
  x = "Literate Proportion of Population",
  y = "Poverty Rate",
  title = "Madhya Pradesh") + 
  theme(
    axis.title = element_text(size = 8), 
    axis.text = element_text(size = 8),
    plot.title = element_text(size = 10)
  ) +
  theme_minimal()

#Assam
plot10 <- as_train_EDA %>%
ggplot(aes(x = lit_rate, y = secc_pov_rate_rural)) +
geom_smooth(alpha = 0.5) +
theme_linedraw() +
labs(
  x = "Literate Proportion of Population",
  y = "Poverty Rate",
  title = "Assam") + 
  theme(
    axis.title = element_text(size = 8), 
    axis.text = element_text(size = 8),
    plot.title = element_text(size = 10)
  ) +
  theme_minimal()

#side-by-side
plot_combined <- plot9 + plot10 +
  plot_annotation(title = "Literacy Rate vs. Poverty Rate")
plot_combined


#F: Poverty Rate by Proportion of Agricultural Employment

#create var for proportion of workers who are cultivators
mp_train_EDA <- mp_train %>%
  mutate(ag_prop = pc11_pca_main_cl_p/pc11_pca_tot_work_p)
as_train_EDA <- as_train %>%
  mutate(ag_prop = pc11_pca_main_cl_p/pc11_pca_tot_work_p)

#Madhya Pradesh
plot11 <- mp_train_EDA %>%
ggplot(aes(x = ag_prop, y = secc_pov_rate_rural)) +
geom_smooth(alpha = 0.5) +
theme_linedraw() +
labs(
  x = "Proportion of Workers who are Cultivators",
  y = "Poverty Rate",
  title = "Madhya Pradesh") + 
  theme(
    axis.title = element_text(size = 8), 
    axis.text = element_text(size = 8),
    plot.title = element_text(size = 10)
  ) +
  theme_minimal()

#Assam
plot12 <- as_train_EDA %>%
ggplot(aes(x = ag_prop, y = secc_pov_rate_rural)) +
geom_smooth(alpha = 0.5) +
theme_linedraw() +
labs(
  x = "Proportion of Workers who are Cultivators",
  y = "Poverty Rate",
  title = "Assam") + 
  theme(
    axis.title = element_text(size = 8), 
    axis.text = element_text(size = 8),
    plot.title = element_text(size = 10)
  ) +
  theme_minimal()

#side-by-side
plot_combined <- plot11 + plot12  +
  plot_annotation(title = "Agricultural Employment vs. Poverty Rate")
plot_combined
```

#India (overall): geospatial analysis

```{r, message = FALSE, warning = FALSE}
#Reading in shrid shape files
shrid2_open_cpg_drive <- drive_download(file = "shrid2_open_ja.cpg", overwrite = TRUE)
shrid2_open_dbf_drive <- drive_download(file = "shrid2_open_ja.dbf", overwrite = TRUE)
shrid2_open_prj_drive <- drive_download(file = "shrid2_open_ja.prj", overwrite = TRUE)
shrid2_open_shp_drive <- drive_download(file = "shrid2_open_ja.shp", overwrite = TRUE)
shrid2_open_shx_drive <- drive_download(file = "shrid2_open_ja.shx", overwrite = TRUE)
```

```{r, message = FALSE, warning = FALSE}
#Reading in shape file and perform
  #a data transformation
shrid <- st_read("shrid2_open_ja.shp", quiet = TRUE)
shrid <- st_transform(shrid, crs = 4326)

#Reading in shape file
shrid_v2 <- readOGR("shrid2_open_ja.shp")
```

```{r, message = FALSE, warning = FALSE}
#Merging together SECC consumption data
#and shrid boundaries
secc_merged <- merge(secc_cons, shrid, by = c("shrid2"))
india_map <- merge(shrid_v2, secc_merged, by = c("shrid2"))

#Converting data
india_map <- st_as_sf(india_map)

#Removing missing data from poverty rate column
india_map <- india_map %>%
  filter(!is.na(secc_pov_rate_rural))

#Continuing to transform data
#into form in which we can map into
india_map <- st_transform(india_map, crs = 4326)
```

```{r, message = FALSE, warning = FALSE}
#Creating map of rural poverty in India
india_map %>% 
  ggplot() +
  geom_sf(color = NA, aes(fill = secc_pov_rate_rural)) +
  labs(title = "Mapping poverty in India",
       fill = "Rural poverty rate")
```

#Madhya Pradesh: geospatial analysis

```{r, message = FALSE, warning = FALSE}
#Creating a map like the previous one but filtering
  #to just shrids in MP
india_map %>%
  filter(SS == 23) %>% 
  ggplot() +
  geom_sf(color = NA, aes(fill = secc_pov_rate_rural)) +
  labs(title = "Mapping poverty in Madhya Pradesh",
       fill = "Rural poverty rate")
```

#Assam: geospatial analysis

```{r, message = FALSE, warning = FALSE}
#Creating a map like the previous one but filtering
  #to just shrids in Assam
india_map %>%
  filter(SS == 18) %>% 
  ggplot() +
  geom_sf(color = NA, aes(fill = secc_pov_rate_rural)) +
  labs(title = "Mapping poverty in Assam",
       fill = "Rural poverty rate")
```

```{r, message = FALSE, warning = FALSE}
#Removing files for shape files
file.remove("shrid2_open_ja.cpg")
file.remove("shrid2_open_ja.dbf")
file.remove("shrid2_open_ja.prj")
file.remove("shrid2_open_ja.shp")
file.remove("shrid2_open_ja.shx")
```
#Regression

##Assam

```{r, message = FALSE, warning = FALSE}
# Filter only numeric columns, dropping missing values
as_train <- as_train %>%
  select_if(is.numeric) %>%
  na.omit()

as_test <- as_test %>%
  select_if(is.numeric) %>%
  na.omit()
```

```{r, message = FALSE, warning = FALSE}
#Dropping a few more variables
as_train <- as_train %>%
  select(-c(viirs_annual_min, viirs_annual_max, viirs_annual_sum,
    viirs_annual_num_cells, secc_cons_pc_rural,
    secc_cons_pc_rural, secc_pov_rate_tend_rural, secc_cons_rural, secc_hh, 
    `_mean_p_miss.x`, `_mean_p_miss.y`, `_mean_p_miss`))
as_test <- as_test %>%
  select(-c(viirs_annual_min, viirs_annual_max, viirs_annual_sum,
    viirs_annual_num_cells, secc_cons_pc_rural,
    secc_cons_pc_rural, secc_pov_rate_tend_rural, secc_cons_rural, secc_hh,
    `_mean_p_miss.x`, `_mean_p_miss.y`, `_mean_p_miss`))
```

```{r, message = FALSE, warning = FALSE}
# Assam: Since lasso was giving error message for vars with 0 variance, this is to check which vars have 0 variance

#near_zero_vars <- nearZeroVar(as_train, saveMetrics = TRUE)
#print(near_zero_vars)

#near_zero_var_names <- names(as_train)[near_zero_vars$zeroVar]
#print(near_zero_var_names)

# dropping some columns that are not useful and were not working with step_scale()
#as_train <-
  #as_train %>%
  #select(-c(category, SS.x, `_target_weight_share.x`, YY.y, bond_lab_share, `_core_p_miss.y`, `_target_group_max_weight_share.y`, SS.x.x, `_target_group_max_weight_share`, SS.y.y, YY.x, `_core_p_miss.x`, `_target_group_max_weight_share.x`, SS.y, scav_share, `_target_weight_share.y`, YY.x.x, `_target_weight_share`, YY.y.y, year, shrid2.x, shrid2.x.x, shrid2.y, shrid2.y.y, TTTTTT))

#as_test <-
  #as_test %>%
  #select(-c(category, SS.x, `_target_weight_share.x`, YY.y, bond_lab_share, `_core_p_miss.y`, `_target_group_max_weight_share.y`, SS.x.x, `_target_group_max_weight_share`, SS.y.y, YY.x, `_core_p_miss.x`, `_target_group_max_weight_share.x`, SS.y, scav_share, `_target_weight_share.y`, YY.x.x, `_target_weight_share`, YY.y.y, year, shrid2.x, shrid2.x.x, shrid2.y, shrid2.y.y, TTTTTT))
```

###Model 1 - CART

We should possibly cut this model out.

```{r, message = FALSE, warning = FALSE}
#Coming up with a recipe for all the Assam models
as_rec <- recipe(formula = secc_pov_rate_rural ~ ., data = as_train) %>%
  step_zv(all_predictors()) %>%
  step_select(all_numeric()) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors()) %>%
  prep()
```

```{r, message = FALSE, warning = FALSE}
#setting seed and v-fold cross-validation
set.seed(04281998)
folds <- vfold_cv(data = as_train, v = 10, repeats = 1) 
```

```{r, message = FALSE, warning = FALSE}
#coming up with a cart mod
cart_mod <-
  decision_tree() %>%
  set_engine(engine = "rpart", model = TRUE) %>%
  set_mode(mode = "regression")

#Creating workflow 
cart_wf <- workflow() %>%
  add_recipe(as_rec) %>%
  add_model(cart_mod)

#Fitting the model
cart_fit <- cart_wf %>%
  fit(data = as_train)

#Creating a tree
tree_model <- rpart.plot::rpart.plot(x = cart_fit$fit$fit$fit, roundint = FALSE)
```

```{r, message = FALSE, warning = FALSE}
#Plotting Variable Importance Plot (VIP)
cart_fit %>%
extract_fit_parsnip() %>%
vip(num_features = 10)
```

###Model 2: Linear Regression

```{r, message = FALSE, warning = FALSE}
#create model object
lm_mod <- linear_reg() %>%
  set_engine("lm")

# create a workflow
lm_wf <- workflow() %>%
  add_recipe(as_rec) %>%
  add_model(lm_mod) 

#function needed to extract coefficients
get_lm_coefs <- function(x) {
  
  x %>% 
    extract_fit_engine() %>% 
    tidy()
}

tidy_ctrl <- control_grid(extract = get_lm_coefs)

#fit 
lm_cv <- lm_wf %>%
  fit_resamples(resamples = folds, control = tidy_ctrl)

#measure RMSE 
collect_metrics(lm_cv, summarize = FALSE) %>%
 filter(.metric == "rmse") %>%
 ggplot(aes(id, .estimate, group = .estimator)) +
 geom_line() +
 geom_point() +
 scale_y_continuous(limits = c(0, 0.5)) +
 labs(title = "Calculated RMSE Across the 10 Folds",
 y = "RMSE_hat") +
 theme_minimal()
```

```{r, message = FALSE, warning = FALSE}
#collecting metrics
metric_table_lm <- collect_metrics(lm_cv, summarize = TRUE)
metric_table_lm %>%
  filter(.metric == "rmse")
```

```{r, message = FALSE, warning = FALSE}
#Getting coefficients
lm_coefs <- lm_cv %>% 
  select(id, .extracts) %>% 
  unnest(.extracts)  %>% 
  unnest(.extracts)

#Getting coefficients for night light
lm_coefs %>%
  filter(term == "viirs_annual_mean")
```

```{r, message = FALSE, warning = FALSE}
#checking the correlation between nlight and poverty rate 
#test <-
#  as_train %>%
#  filter(!is.na(viirs_annual_mean)) %>%
#  filter(!is.na(secc_pov_rate_rural))
#  cor(test$viirs_annual_mean, test$secc_pov_rate_rural)
```

###Model 3: LASSO 

```{r, message = FALSE, warning = FALSE}
#Lasso model
lasso_grid <- grid_regular(penalty(), levels = 10)

lasso_mod <- linear_reg(
  penalty = tune(), 
  mixture = 1,
) %>%
  set_engine("glmnet")

#creating wf
lasso_wf <- workflow() %>%
  add_recipe(as_rec) %>%
  add_model(lasso_mod) 

#fitting wf 
lasso_cv <- lasso_wf %>%
  tune_grid(
    resamples = folds,
    grid = lasso_grid)

#measure RMSE 
collect_metrics(lasso_cv, summarize = FALSE) %>%
 filter(.metric == "rmse") %>%
 ggplot(aes(id, .estimate, group = .estimator)) +
 geom_line() +
 geom_point() +
 scale_y_continuous(limits = c(0, 0.5)) +
 labs(title = "Calculated RMSE Across the 10 Folds",
 y = "RMSE_hat") +
 theme_minimal()
```
```{r, message = FALSE, warning = FALSE}
#collecting metrics
metric_table_lasso <- collect_metrics(lasso_cv, summarize = TRUE)
metric_table_lasso %>%
  filter(.metric == "rmse")
```

```{r, message = FALSE, warning = FALSE}
#selecting model with lowest RMSE
lasso_best <- lasso_cv %>%
  select_best(metric = "rmse")

#finalizing first wf 
lasso_final <- finalize_workflow(
  lasso_wf,
  parameters = lasso_best
)

lasso_coefs <- lasso_final %>%
  fit(data = as_train) %>%
  extract_fit_parsnip() %>%
  vi(lambda = lasso_best$penalty) 

#Coefficients for night light
lasso_coefs %>%
  filter(Variable == "viirs_annual_mean") 
```
###Determining best model

```{r, message = FALSE, warning = FALSE}
bind_rows(
  `lm` = show_best(lm_cv, metric = "rmse", n = 1),
  `lasso` = show_best(lasso_cv, metric = "rmse", n = 1),
  .id = "model")
```

```{r, message = FALSE, warning = FALSE}
#fitting LASSO on testing data 
#lasso_fit <- lasso_final %>%
#  fit(data = as_test)

#create predictions df
#predictions_lasso <-
#  bind_cols(
#    test,
#    stats::predict(object = lasso_fit, new_data = as_test)
#  )

# calculate the rmse on the testing data: 
#rmse(data = predictions_lasso, truth = secc_pov_rate_rural, estimate = .pred)
```

##Madhya Pradesh

```{r, message = FALSE, warning = FALSE}
# Filter only numeric columns, dropping missing values
mp_train <- mp_train %>%
  select_if(is.numeric) %>%
  na.omit()

mp_test <- mp_test %>%
  select_if(is.numeric) %>%
  na.omit()
```

```{r, message = FALSE, warning = FALSE}
#Dropping a few more variables
mp_train <- mp_train %>%
  select(-c(viirs_annual_min, viirs_annual_max, viirs_annual_sum,
    viirs_annual_num_cells, secc_cons_pc_rural,
    secc_cons_pc_rural, secc_pov_rate_tend_rural, secc_cons_rural, secc_hh, 
    `_mean_p_miss.x`, `_mean_p_miss.y`, `_mean_p_miss`))
mp_test <- mp_test %>%
  select(-c(viirs_annual_min, viirs_annual_max, viirs_annual_sum,
    viirs_annual_num_cells, secc_cons_pc_rural,
    secc_cons_pc_rural, secc_pov_rate_tend_rural, secc_cons_rural, secc_hh,
    `_mean_p_miss.x`, `_mean_p_miss.y`, `_mean_p_miss`))
```

###Model 1 - CART

We should possibly cut this model out.

```{r, message = FALSE, warning = FALSE}
#Coming up with a recipe for all the Madhya Pradesh models
mp_rec <- recipe(formula = secc_pov_rate_rural ~ ., data = mp_train) %>%
  step_zv(all_predictors()) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors()) %>%
  prep()
```

```{r, message = FALSE, warning = FALSE}
#setting seed and v-fold cross-validation
set.seed(04281998)
folds <- vfold_cv(data = mp_train, v = 10, repeats = 1) 
```

```{r, message = FALSE, warning = FALSE}
#coming up with a cart mod
cart_mod <-
  decision_tree() %>%
  set_engine(engine = "rpart") %>%
  set_mode(mode = "regression")

#Creating workflow 
cart_wf <- workflow() %>%
  add_recipe(mp_rec) %>%
  add_model(cart_mod)

#Fitting the model
cart_fit <- cart_wf %>%
  fit(data = mp_train)

#Creating a tree
tree_model <- rpart.plot::rpart.plot(x = cart_fit$fit$fit$fit)

```

```{r, message = FALSE, warning = FALSE}
#plotting vip
cart_fit %>%
extract_fit_parsnip() %>%
vip(num_features = 10)

```

###Model 2: Linear Regression

```{r, message = FALSE, warning = FALSE}
#create model object
lm_mod <- linear_reg() %>%
  set_engine("lm")

# create a workflow
lm_wf <- workflow() %>%
  add_recipe(mp_rec) %>%
  add_model(lm_mod) 

#function needed to extract coefficients
get_lm_coefs <- function(x) {
  
  x %>% 
    extract_fit_engine() %>% 
    tidy()
  
}

tidy_ctrl <- control_grid(extract = get_lm_coefs)

#fit 
lm_cv <- lm_wf %>%
  fit_resamples(resamples = folds, control = tidy_ctrl)

#measure RMSE 
collect_metrics(lm_cv, summarize = FALSE) %>%
 filter(.metric == "rmse") %>%
 ggplot(aes(id, .estimate, group = .estimator)) +
 geom_line() +
 geom_point() +
 scale_y_continuous(limits = c(0, 0.5)) +
 labs(title = "Calculated RMSE Across the 10 Folds",
 y = "RMSE_hat") +
 theme_minimal()
```

```{r, message = FALSE, warning = FALSE}
#collecting metrics
metric_table_lm <- collect_metrics(lm_cv, summarize = TRUE)
metric_table_lm %>%
  filter(.metric == "rmse")
```

```{r, message = FALSE, warning = FALSE}
#Getting coefficients
lm_coefs <- lm_cv %>% 
  select(id, .extracts) %>% 
  unnest(.extracts)  %>% 
  unnest(.extracts)

#Getting coefficients for night light
lm_coefs %>%
  filter(term == "viirs_annual_mean")
```

###Model 3: LASSO

```{r, message = FALSE, warning = FALSE}
#Lasso model
lasso_grid <- grid_regular(penalty(), levels = 10)

lasso_mod <- linear_reg(
  penalty = tune(), 
  mixture = 1,
) %>%
  set_engine("glmnet")

#creating wf
lasso_wf <- workflow() %>%
  add_recipe(mp_rec) %>%
  add_model(lasso_mod) 

#fitting wf 
lasso_cv <- lasso_wf %>%
  tune_grid(
    resamples = folds,
    grid = lasso_grid)

#measure RMSE 
collect_metrics(lasso_cv, summarize = FALSE) %>%
 filter(.metric == "rmse") %>%
 ggplot(aes(id, .estimate, group = .estimator)) +
 geom_line() +
 geom_point() +
 scale_y_continuous(limits = c(0, 0.5)) +
 labs(title = "Calculated RMSE Across the 10 Folds",
 y = "RMSE_hat") +
 theme_minimal()
```

```{r, message = FALSE, warning = FALSE}
#collecting metrics
metric_table_lasso <- collect_metrics(lasso_cv, summarize = TRUE)
metric_table_lasso %>%
  filter(.metric == "rmse")
```

```{r, message = FALSE, warning = FALSE}
#selecting model with lowest RMSE
lasso_best <- lasso_cv %>%
  select_best(metric = "rmse")

#finalizing first wf 
lasso_final <- finalize_workflow(
  lasso_wf,
  parameters = lasso_best
)

lasso_coefs <- lasso_final %>%
  fit(data = as_train) %>%
  extract_fit_parsnip() %>%
  vi(lambda = lasso_best$penalty) 

#Coefficients for night light
lasso_coefs %>%
  filter(Variable == "viirs_annual_mean") 
```
###Determining best model

```{r, message = FALSE, warning = FALSE}
bind_rows(
  `lm` = show_best(lm_cv, metric = "rmse", n = 1),
  `lasso` = show_best(lasso_cv, metric = "rmse", n = 1),
  .id = "model")
```

```{r, message = FALSE, warning = FALSE}
#fitting LASSO on testing data 
#lasso_fit <- lasso_final %>%
#  fit(data = as_test)

#create predictions df
#predictions_lasso <-
#  bind_cols(
#    test,
#    stats::predict(object = lasso_fit, new_data = as_test)
#  )

# calculate the rmse on the testing data: 
#rmse(data = predictions_lasso, truth = secc_pov_rate_rural, estimate = .pred)
```

#Classification

##Assam

```{r, message = FALSE, warning = FALSE}
#Creating binary variable
#1: 50%+ of rural households in poverty, 0: under 50% of rural households in poverty
as_train$high_poverty <-
  ifelse(as_train$secc_pov_rate_rural >= 0.5, "Higher", "Lower")
as_test$high_poverty <-
  ifelse(as_test$secc_pov_rate_rural >= 0.5, "Higher", "Lower")
```

```{r, message = FALSE, warning = FALSE}
#Making high_poverty variable factors
as_train$high_poverty <- as.factor(as_train$high_poverty)
as_test$high_poverty <- as.factor(as_test$high_poverty)
```

```{r, message = FALSE, warning = FALSE}
# create a recipe
cart_rec_as <-
  recipe(formula = high_poverty ~ viirs_annual_mean + land_own_share, data = as_train)
# create a cart model object
cart_mod_classification_as <-
  decision_tree() %>%
  set_engine(engine = "rpart") %>%
  set_mode(mode = "classification")
cart_wf_classification_as <- workflow() %>%
  add_recipe(cart_rec_as) %>%
  add_model(cart_mod_classification_as)
# fit the model
cart_fit_classification_as <- 
  cart_wf_classification_as %>%
  fit(data = as_train)
```

```{r, message = FALSE, warning = FALSE}
#Visualizing decision tree
rpart.plot::rpart.plot(x = cart_fit_classification_as$fit$fit$fit)
```

```{r, message = FALSE, warning = FALSE}
#Adding predicted values and probabilities
  #as columns to testing dataset
predictions_as <- bind_cols(
  as_test,
  predict(object = cart_fit_classification_as, new_data = as_test),
  predict(object = cart_fit_classification_as, new_data = as_test, type = "prob")
)
```

```{r, message = FALSE, warning = FALSE}
#Creating confusion matrix
conf_mat(data = predictions_as,
truth = high_poverty,
estimate = .pred_class)
```

```{r, message = FALSE, warning = FALSE}
#Calculating accuracy
accuracy(data = predictions_as,
truth = high_poverty,
estimate = .pred_class)
```

Accuracy: 71%

```{r, message = FALSE, warning = FALSE}
#Calculating precision
precision_vec(data = predictions_as,
truth = predictions_as$high_poverty,
estimate = predictions_as$.pred_class)
```

Precision: 56%

```{r, message = FALSE, warning = FALSE}
#Calculating recall
recall_vec(data = predictions_as,
truth = predictions_as$high_poverty,
estimate = predictions_as$.pred_class)
```

Recall: 23%

##Madhya Pradesh

```{r, message = FALSE, warning = FALSE}
#Creating binary variable
#1: 50%+ of rural households in poverty, 0: under 50% of rural households in poverty
mp_train$high_poverty <-
  ifelse(mp_train$secc_pov_rate_rural >= 0.5, "Higher", "Lower")
mp_test$high_poverty <-
  ifelse(mp_test$secc_pov_rate_rural >= 0.5, "Higher", "Lower")
```

```{r, message = FALSE, warning = FALSE}
#Making high poverty column factors
mp_train$high_poverty <- as.factor(mp_train$high_poverty)
mp_test$high_poverty <- as.factor(mp_test$high_poverty)
```

```{r, message = FALSE, warning = FALSE}
# create a recipe
cart_rec_mp <-
  recipe(formula = high_poverty ~ viirs_annual_mean + land_own_share, data = mp_train)
# create a cart model object
cart_mod_classification_mp <-
  decision_tree() %>%
  set_engine(engine = "rpart") %>%
  set_mode(mode = "classification")
cart_wf_classification_mp <- workflow() %>%
  add_recipe(cart_rec_mp) %>%
  add_model(cart_mod_classification_mp)
# fit the model
cart_fit_classification_mp <- 
  cart_wf_classification_mp %>%
  fit(data = mp_train)
```

```{r, message = FALSE, warning = FALSE}
#Visualizing decision tree
rpart.plot::rpart.plot(x = cart_fit_classification_mp$fit$fit$fit)
```

```{r, message = FALSE, warning = FALSE}
#Adding predicted values and probabilities
  #as columns to testing dataset
predictions_mp <- bind_cols(
  mp_test,
  predict(object = cart_fit_classification_mp, new_data = mp_test),
  predict(object = cart_fit_classification_mp, new_data = mp_test, type = "prob")
)
```

```{r, message = FALSE, warning = FALSE}
#Creating decision tree
conf_mat(data = predictions_mp,
truth = high_poverty,
estimate = .pred_class)
```

```{r, message = FALSE, warning = FALSE}
#Calculating accuracy
accuracy(data = predictions_mp,
truth = high_poverty,
estimate = .pred_class)
```

Accuracy: 68%

```{r, message = FALSE, warning = FALSE}
#Calculating precision
precision_vec(data = predictions_mp,
truth = predictions_mp$high_poverty,
estimate = predictions_mp$.pred_class)
```

Precision: 64%

```{r, message = FALSE, warning = FALSE}
recall_vec(data = predictions_mp,
truth = predictions_mp$high_poverty,
estimate = predictions_mp$.pred_class)
```

Recall: 57%